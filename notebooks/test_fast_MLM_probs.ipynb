{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370b1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/10tb/home/fishman/miniconda3/envs/bert24/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.utils.data import get_worker_info\n",
    "import torch.distributed as dist\n",
    "import transformers\n",
    "from transformers import default_data_collator\n",
    "from transformers import AutoTokenizer\n",
    "from omegaconf import DictConfig, OmegaConf as om\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(111)\n",
    "from collections.abc import Mapping\n",
    "from typing import Optional, Tuple, Union, Any, Dict, List\n",
    "import logging\t\t\n",
    "\n",
    "\n",
    "# Add ModernBERT to path\n",
    "# TODO: add morerngena distr target path argparse\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from src.text_data import NoStreamingGenomeDataset\n",
    "\n",
    "class _GenomeDatasetForMasking(NoStreamingGenomeDataset):\n",
    "\tdef __getitem__(self, index: int):\n",
    "\t\tshard_id, shard_sample_id = self.spanner[index]\n",
    "\t\tshard = self.shards[shard_id]\n",
    "\t\tsample = shard[shard_sample_id]\n",
    "\t\treturn sample['file_id'], sample['line_id'], shard_id\n",
    "\n",
    "\n",
    "data_dir= \"/mnt/nfs_dna/shadskiy/promoters/pretrena/mds_v2/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/gena-lm-bert-base-t2t\")\n",
    "# Create dataset\n",
    "ds = _GenomeDatasetForMasking(\n",
    "\tlocal=data_dir,\n",
    "\tsplit=\"train\",\n",
    "\tmax_seq_len=1024,\n",
    "\ttokenizer = tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 458/13525034 [00:02<18:06:02, 207.55it/s]"
     ]
    }
   ],
   "source": [
    "genomes = set()\n",
    "last_shard=30\n",
    "for i in tqdm(range(0,len(ds),1)):\n",
    "\t_ = ds[i]\n",
    "\tgenome = _[0]\n",
    "\tshard_id = _[2]\n",
    "\tif shard_id>last_shard:\n",
    "\t\tprint (shard_id)\n",
    "\t\tbreak\n",
    "\t# if genome.find(\"GCF_000001405\")!=-1:\n",
    "\t# \tprint (i)\n",
    "\t# \tprint (genome)\n",
    "\t# \tbreak\n",
    "\t# else:\n",
    "\t# \tgenomes.add(genome)\n",
    "print (len(genomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64dfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
