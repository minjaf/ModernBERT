{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370b1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/10tb/home/fishman/miniconda3/envs/bert24/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.utils.data import get_worker_info\n",
    "import torch.distributed as dist\n",
    "import transformers\n",
    "from transformers import default_data_collator\n",
    "from transformers import AutoTokenizer\n",
    "from omegaconf import DictConfig, OmegaConf as om\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(111)\n",
    "from collections.abc import Mapping\n",
    "from typing import Optional, Tuple, Union, Any, Dict, List\n",
    "import logging\t\t\n",
    "\n",
    "\n",
    "# Add ModernBERT to path\n",
    "# TODO: add morerngena distr target path argparse\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from src.text_data import NoStreamingGenomeDataset\n",
    "\n",
    "class _GenomeDatasetForMasking(NoStreamingGenomeDataset):\n",
    "\tdef __getitem__(self, index: int):\n",
    "\t\tshard_id, shard_sample_id = self.spanner[index]\n",
    "\t\tshard = self.shards[shard_id]\n",
    "\t\tsample = shard[shard_sample_id]\n",
    "\t\treturn sample['file_id'], sample['line_id'], shard_id\n",
    "\n",
    "\n",
    "data_dir= \"/mnt/nfs_dna/shadskiy/promoters/pretrena/mds_v2/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/gena-lm-bert-base-t2t\")\n",
    "# Create dataset\n",
    "ds = _GenomeDatasetForMasking(\n",
    "\tlocal=data_dir,\n",
    "\tsplit=\"train\",\n",
    "\tmax_seq_len=1024,\n",
    "\ttokenizer = tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = set()\n",
    "last_shard=30\n",
    "for i in tqdm(range(0,len(ds),1)):\n",
    "\t_ = ds[i]\n",
    "\tgenome = _[0]\n",
    "\tshard_id = _[2]\n",
    "\tif shard_id>last_shard:\n",
    "\t\tprint (i,shard_id)\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tif i % 5000 == 0:\n",
    "\t\t\tprint (i,shard_id)\n",
    "\t# if genome.find(\"GCF_000001405\")!=-1:\n",
    "\t# \tprint (i)\n",
    "\t# \tprint (genome)\n",
    "\t# \tbreak\n",
    "\t# else:\n",
    "\t# \tgenomes.add(genome)\n",
    "print (len(genomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c64dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0  2586  5093  7654 10256]\n"
     ]
    }
   ],
   "source": [
    "print (ds.spanner.shard_bounds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd15f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2586"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.shards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "782fae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(\"../runs/test/mlm_efficiency/train/shard_0.hdf5\", \"r\") as f:\n",
    "\tdata = f['0'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d0c772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11434, 11434)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sum(), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18bee2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abbf20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bool(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfd353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"../runs/test/test.h5\",\"w\") as f:\n",
    "\tfor _ in range(100):\n",
    "\t\tf.create_dataset(str(_), \n",
    "\t\t\t\tdata = np.zeros(shape=(3000,), dtype=bool), \n",
    "\t\t\t\tdtype=bool\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa0d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 31, 11, 6, 8, 16, 15, 21, 47, 17, 13, 42, 20, 43, 41, 4, 34, 14, 39, 45, 25, 3, 29, 9, 33, 32, 37, 35, 46, 19, 18, 1, 27, 10, 44, 22, 23, 28, 24, 5, 0, 40, 2, 30, 12, 49, 36, 38, 7, 48]\n",
      "Variant1  0:00:00.293402\n",
      "Variant2  0:00:00.142648\n"
     ]
    }
   ],
   "source": [
    "# test time\n",
    "import datetime\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# ids = [2,3,7]\n",
    "ids = np.arange(50)\n",
    "ids = np.random.permutation(ids).tolist()\n",
    "print (ids)\n",
    "\n",
    "_ = datetime.datetime.now()\n",
    "random.seed(23)\n",
    "for repeat in range(100):\n",
    "\twith h5py.File(\"../runs/test/test.h5\",\"a\") as f:\n",
    "\t\tsample = random.randint(0,99)\n",
    "\t\tdata = f[str(sample)][:]\n",
    "\t\t\n",
    "\t\tdata[ids] = True\n",
    "\t\tf[str(sample)][:] = data  # Modify existing dataset in-place\n",
    "timedelta = datetime.datetime.now() - _\n",
    "print (\"Variant1 \", timedelta)\n",
    "\n",
    "_ = datetime.datetime.now()\n",
    "random.seed(23)\n",
    "for repeat in range(10):\n",
    "\twith h5py.File(\"../runs/test/test.h5\",\"a\") as f:\n",
    "\t\tsample = random.randint(0,99)\n",
    "\t\tfor i in ids:\n",
    "\t\t\tf[str(sample)][i] = True\n",
    "timedelta = datetime.datetime.now() - _\n",
    "print (\"Variant2 \", timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c626b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
